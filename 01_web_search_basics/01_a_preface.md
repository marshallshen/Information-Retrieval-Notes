# Web search basics
## Preface

How is web search different from traditional information retrieval?
----------------------------------------------------------------------
## Web is messy

1. Web has decentralized content publishing with no central control of authorship.
2. Web contents have different level of authorities.
3. Web contents have different opinions that may speak contrast views about a topic.
4. Web contents change all the time.

How to evaluate web pages?
----------------------------------------------------------------------
1. Web consists of 1) static HTML pages 2) links between them
2. If page A links to page B, text on the hyperlink from A to B is `anchor text`
3. Two types of links: `in-links` and `out-links`.
4. Distribution of the number of links into a web page follows a `power law`: total number web pages with in-degree i is proportional to 1/i (Zipf's Law)

Spam and Spam detection
----------------------------------------------------------------------
1. Web content creators have commerical motives to gain from manipulating search engine results.
2. Given that spamming is inherently an economically motivated activity, an industry of `Search Engine Optimizers` is born.

Query needs
----------------------------------------------------------------------
1. `Informational`: seek general information on a broad topic (e.x. Best retaurants in NYC)
2. `Navigational`: seek the website or home page of a single entity (e.x. Columbia Univeristy homepage)
3. `Transactional`: a prelude to the user performing a transaction on the Web (e.x. Gifts for Christmas)

## Other references

`Zipf's law`: if t_1 is the most common term in the collection, t_2 is the next most common, and so on, then the collection frequency cf_i of the i_th most common term is proportional to 1/i